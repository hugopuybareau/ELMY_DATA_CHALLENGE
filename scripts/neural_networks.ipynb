{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "import numpy as np\n",
    "import importlib\n",
    "import functions\n",
    "import pandas as pd\n",
    "\n",
    "# Data engineering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "import xgboost as xgb\n",
    "\n",
    "# Neural Networks\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Functions imports\n",
    "importlib.reload(functions)\n",
    "from functions import *\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(\"../data/processed/x_processed.csv\")  # 10605 rows × 10 columns\n",
    "x_challenge = pd.read_csv(\"../data/processed/x_challenge_processed.csv\")  # 4942 rows × 10 columns\n",
    "x_challenge_unprocessed = pd.read_csv(\"../data/raw/X_test_GgyECq8.csv\")\n",
    "y = pd.read_csv(\"../data/raw/y_train_jJtXgMX.csv\")  # 10605 rows × 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DELIVERY_START</th>\n",
       "      <th>spot_id_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 02:00:00+01:00</td>\n",
       "      <td>-36.874770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 03:00:00+01:00</td>\n",
       "      <td>-12.643588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 04:00:00+01:00</td>\n",
       "      <td>-1.950193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 05:00:00+01:00</td>\n",
       "      <td>1.938272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 06:00:00+01:00</td>\n",
       "      <td>0.199907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DELIVERY_START  spot_id_delta\n",
       "0  2022-01-01 02:00:00+01:00     -36.874770\n",
       "1  2022-01-01 03:00:00+01:00     -12.643588\n",
       "2  2022-01-01 04:00:00+01:00      -1.950193\n",
       "3  2022-01-01 05:00:00+01:00       1.938272\n",
       "4  2022-01-01 06:00:00+01:00       0.199907"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x.drop(columns=['DELIVERY_START']), y, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load_forecast</th>\n",
       "      <th>coal_power_available</th>\n",
       "      <th>gas_power_available</th>\n",
       "      <th>nuclear_power_available</th>\n",
       "      <th>wind_power_forecasts_average</th>\n",
       "      <th>solar_power_forecasts_average</th>\n",
       "      <th>wind_power_forecasts_std</th>\n",
       "      <th>solar_power_forecasts_std</th>\n",
       "      <th>predicted_spot_price</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>month</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_peak_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6889</th>\n",
       "      <td>-1.492528</td>\n",
       "      <td>-0.027836</td>\n",
       "      <td>0.995779</td>\n",
       "      <td>-0.566640</td>\n",
       "      <td>0.058365</td>\n",
       "      <td>-0.707845</td>\n",
       "      <td>-0.503496</td>\n",
       "      <td>-0.595488</td>\n",
       "      <td>-1.167643</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9822</th>\n",
       "      <td>0.269885</td>\n",
       "      <td>1.143747</td>\n",
       "      <td>0.995779</td>\n",
       "      <td>0.568604</td>\n",
       "      <td>-0.359260</td>\n",
       "      <td>-0.266490</td>\n",
       "      <td>-0.753250</td>\n",
       "      <td>0.745202</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6933</th>\n",
       "      <td>-0.794831</td>\n",
       "      <td>-0.027836</td>\n",
       "      <td>0.034590</td>\n",
       "      <td>-0.686070</td>\n",
       "      <td>0.144329</td>\n",
       "      <td>-0.707845</td>\n",
       "      <td>1.724267</td>\n",
       "      <td>-0.595488</td>\n",
       "      <td>-0.153274</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>1.405688</td>\n",
       "      <td>0.982149</td>\n",
       "      <td>0.049060</td>\n",
       "      <td>1.051706</td>\n",
       "      <td>1.066434</td>\n",
       "      <td>0.679798</td>\n",
       "      <td>-0.479123</td>\n",
       "      <td>0.167050</td>\n",
       "      <td>1.226557</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>0.076341</td>\n",
       "      <td>1.143747</td>\n",
       "      <td>1.010248</td>\n",
       "      <td>1.022045</td>\n",
       "      <td>-0.519290</td>\n",
       "      <td>-0.707845</td>\n",
       "      <td>-0.477909</td>\n",
       "      <td>-0.595488</td>\n",
       "      <td>0.102357</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      load_forecast  coal_power_available  gas_power_available  \\\n",
       "6889      -1.492528             -0.027836             0.995779   \n",
       "9822       0.269885              1.143747             0.995779   \n",
       "6933      -0.794831             -0.027836             0.034590   \n",
       "1217       1.405688              0.982149             0.049060   \n",
       "1475       0.076341              1.143747             1.010248   \n",
       "\n",
       "      nuclear_power_available  wind_power_forecasts_average  \\\n",
       "6889                -0.566640                      0.058365   \n",
       "9822                 0.568604                     -0.359260   \n",
       "6933                -0.686070                      0.144329   \n",
       "1217                 1.051706                      1.066434   \n",
       "1475                 1.022045                     -0.519290   \n",
       "\n",
       "      solar_power_forecasts_average  wind_power_forecasts_std  \\\n",
       "6889                      -0.707845                 -0.503496   \n",
       "9822                      -0.266490                 -0.753250   \n",
       "6933                      -0.707845                  1.724267   \n",
       "1217                       0.679798                 -0.479123   \n",
       "1475                      -0.707845                 -0.477909   \n",
       "\n",
       "      solar_power_forecasts_std  predicted_spot_price  hour  day_of_week  \\\n",
       "6889                  -0.595488             -1.167643     1            1   \n",
       "9822                   0.745202              0.049341     7            5   \n",
       "6933                  -0.595488             -0.153274    21            2   \n",
       "1217                   0.167050              1.226557     9            1   \n",
       "1475                  -0.595488              0.102357     3            5   \n",
       "\n",
       "      day_of_month  month  is_weekend  is_peak_hour  \n",
       "6889            25     10           0             0  \n",
       "9822            25      2           0             1  \n",
       "6933            26     10           0             0  \n",
       "1217            22      2           0             1  \n",
       "1475             5      3           0             0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hugopuybareau/Documents/GitHub/ELMY_DATA_CHALLENGE/env3/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))  # Couche de sortie pour la régression\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 1819.4917 - val_loss: 974.7173\n",
      "Epoch 2/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - loss: 2063.1479 - val_loss: 972.7306\n",
      "Epoch 3/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - loss: 1717.3191 - val_loss: 968.2651\n",
      "Epoch 4/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 1502.6162 - val_loss: 962.5804\n",
      "Epoch 5/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - loss: 1127.8595 - val_loss: 959.5595\n",
      "Epoch 6/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 1453.1357 - val_loss: 959.9280\n",
      "Epoch 7/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - loss: 1538.3000 - val_loss: 953.7562\n",
      "Epoch 8/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - loss: 1750.9917 - val_loss: 954.3129\n",
      "Epoch 9/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - loss: 1688.3296 - val_loss: 948.4973\n",
      "Epoch 10/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - loss: 1723.2424 - val_loss: 943.3599\n",
      "Epoch 11/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - loss: 1627.7457 - val_loss: 934.6404\n",
      "Epoch 12/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - loss: 1181.8481 - val_loss: 931.7605\n",
      "Epoch 13/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - loss: 1350.0955 - val_loss: 929.9872\n",
      "Epoch 14/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - loss: 1543.6643 - val_loss: 932.6143\n",
      "Epoch 15/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - loss: 1226.0017 - val_loss: 924.3976\n",
      "Epoch 16/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - loss: 1549.7832 - val_loss: 926.2119\n",
      "Epoch 17/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 1303.0232 - val_loss: 924.1896\n",
      "Epoch 18/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - loss: 2717.0730 - val_loss: 922.2469\n",
      "Epoch 19/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - loss: 1741.5234 - val_loss: 916.7320\n",
      "Epoch 20/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - loss: 1499.9176 - val_loss: 911.0359\n",
      "Epoch 21/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - loss: 1375.6124 - val_loss: 907.7762\n",
      "Epoch 22/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - loss: 1622.6332 - val_loss: 905.4106\n",
      "Epoch 23/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - loss: 1621.8634 - val_loss: 911.7206\n",
      "Epoch 24/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - loss: 2172.5417 - val_loss: 904.1589\n",
      "Epoch 25/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - loss: 1117.2820 - val_loss: 900.5289\n",
      "Epoch 26/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - loss: 2829.8093 - val_loss: 896.9727\n",
      "Epoch 27/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - loss: 1278.2772 - val_loss: 893.7839\n",
      "Epoch 28/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - loss: 1671.6315 - val_loss: 891.6905\n",
      "Epoch 29/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - loss: 1877.1736 - val_loss: 888.6531\n",
      "Epoch 30/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - loss: 2191.2903 - val_loss: 885.7610\n",
      "Epoch 31/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - loss: 2095.6519 - val_loss: 887.8154\n",
      "Epoch 32/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - loss: 1283.9176 - val_loss: 892.0959\n",
      "Epoch 33/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - loss: 1250.5153 - val_loss: 880.2357\n",
      "Epoch 34/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - loss: 976.8638 - val_loss: 893.0389\n",
      "Epoch 35/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - loss: 1009.4073 - val_loss: 875.1916\n",
      "Epoch 36/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - loss: 1997.3744 - val_loss: 870.0670\n",
      "Epoch 37/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - loss: 1091.2867 - val_loss: 867.5139\n",
      "Epoch 38/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - loss: 1806.3582 - val_loss: 862.7395\n",
      "Epoch 39/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - loss: 1515.1211 - val_loss: 867.8198\n",
      "Epoch 40/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - loss: 1059.6465 - val_loss: 862.9048\n",
      "Epoch 41/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - loss: 1288.7281 - val_loss: 859.8127\n",
      "Epoch 42/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 1690.4037 - val_loss: 857.4753\n",
      "Epoch 43/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - loss: 1130.8494 - val_loss: 860.5823\n",
      "Epoch 44/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - loss: 1531.7603 - val_loss: 855.9903\n",
      "Epoch 45/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - loss: 1508.5771 - val_loss: 853.8458\n",
      "Epoch 46/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 1199.5250 - val_loss: 850.4200\n",
      "Epoch 47/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - loss: 1375.7979 - val_loss: 846.2859\n",
      "Epoch 48/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - loss: 1753.1556 - val_loss: 843.5579\n",
      "Epoch 49/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - loss: 1647.7286 - val_loss: 844.9120\n",
      "Epoch 50/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - loss: 969.3690 - val_loss: 851.4515\n",
      "Epoch 51/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - loss: 1546.4861 - val_loss: 842.0845\n",
      "Epoch 52/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - loss: 1702.9854 - val_loss: 843.9178\n",
      "Epoch 53/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 1593.4587 - val_loss: 839.5667\n",
      "Epoch 54/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - loss: 1101.2024 - val_loss: 841.0134\n",
      "Epoch 55/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - loss: 1198.3441 - val_loss: 836.6509\n",
      "Epoch 56/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - loss: 1246.4919 - val_loss: 838.4677\n",
      "Epoch 57/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - loss: 1720.1284 - val_loss: 834.0540\n",
      "Epoch 58/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - loss: 1241.3734 - val_loss: 833.9318\n",
      "Epoch 59/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - loss: 1014.2211 - val_loss: 851.8489\n",
      "Epoch 60/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - loss: 1409.1193 - val_loss: 835.0510\n",
      "Epoch 61/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - loss: 1081.3038 - val_loss: 833.7910\n",
      "Epoch 62/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - loss: 1093.9493 - val_loss: 834.0342\n",
      "Epoch 63/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 1708.8179 - val_loss: 831.9363\n",
      "Epoch 64/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - loss: 1171.6595 - val_loss: 832.5987\n",
      "Epoch 65/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - loss: 1827.4016 - val_loss: 824.9657\n",
      "Epoch 66/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - loss: 1691.4899 - val_loss: 827.8996\n",
      "Epoch 67/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - loss: 1193.1002 - val_loss: 825.8961\n",
      "Epoch 68/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - loss: 1076.1897 - val_loss: 846.9873\n",
      "Epoch 69/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - loss: 1843.6432 - val_loss: 825.5176\n",
      "Epoch 70/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - loss: 1105.4065 - val_loss: 824.6463\n",
      "Epoch 71/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - loss: 934.9383 - val_loss: 831.3210\n",
      "Epoch 72/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - loss: 1264.1724 - val_loss: 825.8534\n",
      "Epoch 73/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - loss: 1485.6010 - val_loss: 822.5101\n",
      "Epoch 74/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - loss: 1294.8662 - val_loss: 816.1228\n",
      "Epoch 75/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - loss: 1173.2872 - val_loss: 810.9950\n",
      "Epoch 76/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - loss: 982.0380 - val_loss: 811.7717\n",
      "Epoch 77/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - loss: 1247.0039 - val_loss: 807.2588\n",
      "Epoch 78/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - loss: 846.3936 - val_loss: 817.7310\n",
      "Epoch 79/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - loss: 910.8347 - val_loss: 823.0163\n",
      "Epoch 80/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - loss: 872.9313 - val_loss: 813.5350\n",
      "Epoch 81/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - loss: 1278.5160 - val_loss: 816.2086\n",
      "Epoch 82/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - loss: 1072.8544 - val_loss: 807.7561\n",
      "Epoch 83/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - loss: 1646.4031 - val_loss: 800.2424\n",
      "Epoch 84/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - loss: 999.8581 - val_loss: 810.1608\n",
      "Epoch 85/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - loss: 1692.5743 - val_loss: 805.2987\n",
      "Epoch 86/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - loss: 947.8301 - val_loss: 803.4163\n",
      "Epoch 87/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - loss: 965.5552 - val_loss: 800.3156\n",
      "Epoch 88/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - loss: 1096.6696 - val_loss: 799.4786\n",
      "Epoch 89/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - loss: 1002.4355 - val_loss: 808.0480\n",
      "Epoch 90/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - loss: 1297.2855 - val_loss: 787.2088\n",
      "Epoch 91/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - loss: 952.2114 - val_loss: 796.6768\n",
      "Epoch 92/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - loss: 1048.4436 - val_loss: 798.6323\n",
      "Epoch 93/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 1150.3610 - val_loss: 789.7576\n",
      "Epoch 94/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - loss: 1022.4614 - val_loss: 777.3136\n",
      "Epoch 95/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - loss: 903.9747 - val_loss: 802.2692\n",
      "Epoch 96/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 967.6696 - val_loss: 783.1098\n",
      "Epoch 97/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - loss: 926.3798 - val_loss: 785.0973\n",
      "Epoch 98/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - loss: 910.9385 - val_loss: 782.9362\n",
      "Epoch 99/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - loss: 1021.8574 - val_loss: 777.4620\n",
      "Epoch 100/100\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - loss: 1288.7208 - val_loss: 776.5037\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223us/step - loss: 976.1419\n",
      "Mean Squared Error on Test Set: 1001.5025634765625\n"
     ]
    }
   ],
   "source": [
    "# Entraînement du modèle\n",
    "model.fit(x_train, y_train['spot_id_delta'], epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Évaluation du modèle sur l'ensemble de test\n",
    "mse = model.evaluate(x_test, y_test['spot_id_delta'])\n",
    "print(f'Mean Squared Error on Test Set: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DELIVERY_START</th>\n",
       "      <th>spot_id_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-02 00:00:00+02:00</td>\n",
       "      <td>5.094093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-02 01:00:00+02:00</td>\n",
       "      <td>2.513124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-02 02:00:00+02:00</td>\n",
       "      <td>0.354792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-02 03:00:00+02:00</td>\n",
       "      <td>0.142496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-02 04:00:00+02:00</td>\n",
       "      <td>-0.230233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DELIVERY_START  spot_id_delta\n",
       "0  2023-04-02 00:00:00+02:00       5.094093\n",
       "1  2023-04-02 01:00:00+02:00       2.513124\n",
       "2  2023-04-02 02:00:00+02:00       0.354792\n",
       "3  2023-04-02 03:00:00+02:00       0.142496\n",
       "4  2023-04-02 04:00:00+02:00      -0.230233"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prédictions\n",
    "y_challenge = pd.DataFrame({ # Faut prendre 'x_challenge_unprocessed' sinon il y aura le décalage horaire.\n",
    "    'DELIVERY_START' : x_challenge_unprocessed['DELIVERY_START']  \n",
    "    })\n",
    "\n",
    "y_challenge['spot_id_delta'] = model.predict(x_challenge.drop(columns=['DELIVERY_START']))\n",
    "\n",
    "\n",
    "y_challenge.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_challenge.to_csv(\"../data/predicted/y_challenge_11.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# J'ai toujours le même problème sur ce challenge. J'ai beau entraîner des modèles de plus en plus complexes,\n",
    "# les résultats ne sont pas plus concluants car la corrélation entre les données d'entraînement et les données \n",
    "# de soumission n'est pas la même. Toutes les relations apprises par mes algorithmes lors de l'entraînement, sont \n",
    "# en fait inutile pour la prédiction sur les données de soumission. \n",
    "\n",
    "# C'est un problème d'overfitting que je n'arrive pas à régler en pré-traitement ou en prédiction. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
